---
title: Cross-season correspondence dataset Note
date: 2019-09-13 20:48:09
cover: /img/cover2.jpg
tags: Deep-Learning
---
## 用于鲁棒语义分割的跨季节对应关系数据集  
## Notes of Cross season correspondence datasets  

---
**Datasets**: *[Visual Localization](https://www.visuallocalization.net/)*  
**Code**: *[Cross Season Segmentation](https://github.com/maunzzz/cross-season-segmentation)*  
**Paper**：*[A Cross-Season Correspondence Dataset for Robust Semantic Segmentation](https://arxiv.org/abs/1903.06916) 用于鲁棒语义分割的跨季节对应关系数据库*  

这篇论文发布在CVPR2019上，描述了一种基于对应关系的跨季节数据集，这一数据集提出了一种新的方法来提高神经网络在跨季节数据集上的语义分割性能，使用文章提出的方法能有效提高语义分割的准确性，并且能极大地降低数据集中图片标签的人工标注成本。  

在文章中，作者提出利用不同摄像条件下(光照、季节变换)拍摄的2D-2D点匹配来训练卷积神经网络，测试结果表明在训练过程中添加跨季节变化及白天到晚上的像素对应关系作为额外监督能提高神经网络进行语义分割的性能，使其在应对季节和天气条件的变化时更加稳健。

那么问题来了，什么是**语义分割**?  
### **语义分割Semantic Segmentation**  
---
人类如何描述看到的场景呢？我们可能会这么描述：图片中有一栋靠近街道的房子，房子周围环绕着修剪好的灌木，路边停着一辆白色的车。不难发现，人类对于图像的理解的关键之一在于将作为一个整体的图片分割为多个实体来理解，这样有助于我们区分静止的背景和运动的实体，进而能预测和分析目标可能出现的行为。而语义分割就是计算机视觉中将场景分割为实体的方法。通俗来讲，语义分割有助于计算机理解图片中各个不同实体的含义。下图以可视化的方式展示了常见语义分割方法的效果：  

<div align=center>
<img src="./Cross-season-correspondence-dataset-Note/sem_seg_eg1.gif")>  
语义分割效果示例
</div>

而语义分割的主要任务就是将标签分配给图像的每个像素，作为计算机视觉的基本任务之一，语义分割也用于更高级别的场景理解，如密集的3D重建、SLAM即时定位与地图构建、SFM运动恢复结构和位置识别等等。由于当前正在发展的无人驾驶和智能机器人技术，精确的语义分割变得越来越重要。

### **训练集标注方法**
近年来，随着神经网络的进步，语义分割的性能在不断地增长，经过良好训练的语义分割网络能达到很高的语义分割性能，但训练这些网络需要大量经过人工精注释的图像。对一个动辄数万张图片的数据集进行人工标注无疑是非常耗时费力的工作，目前提出的降低成本的弱监督方法是使用边界框标签、图像级标签或点标签来进行注释，而论文中则提出使用一种半自动获取图片对应关系的方法来代替人工标注的方法。  

这种方法基于以下的基本思想，即: *场景的语义含义在季节等环境变化的条件下不发生变化，因此才能在图像外观的匹配失效时通过语义建立2D-3D匹配.*  
论文提出通过寻找在不同条件下拍摄的同一场景的多张图片中的对应关系来对图片进行标注，首先通过图像几何匹配的方法来建立3D模型，通过3D模型和2D图片中的对应点来建立两张图片中的2D-2D匹配关系，由于不同的季节和光照条件下，实体的语义不发生变化，因此可以认为这些对2D-2D匹配点所含的语义是相同的。由此将两张图片的匹配点赋予相同对应关系的标签，并将这种对应关系的约束加入到训练过程中。 
<div align=center> 
<img src="./Cross-season-correspondence-dataset-Note/correspondence_eg1.jpg" width="400" height="297" >  
2D-2D匹配和对应关系的建立
</div>

### **实现过程**  
### **损失函数的改进**  
### **在不同数据集下的效果**  
### **发展方向**